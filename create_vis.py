import pickle
import matplotlib.pyplot as plt
from mlxtend.plotting import plot_confusion_matrix


res_RL_WN ={'CNN train_loss_list': [0.6958057284355164, 0.6930960416793823, 0.6926529407501221, 0.6918925046920776, 0.6914997100830078, 0.6895506381988525, 0.6869117617607117, 0.6820853352546692, 0.6773020625114441, 0.662178635597229, 0.6440454721450806, 0.6292213201522827, 0.5889046788215637, 0.5478882193565369, 0.4967164993286133, 0.4272269308567047, 0.3450983464717865, 0.25431182980537415, 0.16468729078769684, 0.09531116485595703, 0.05269724130630493, 0.03186358883976936, 0.02211790345609188, 0.016574757173657417, 0.013211310841143131, 0.011051603592932224, 0.009488808922469616, 0.00832605641335249, 0.007429172284901142, 0.006687203887850046], 'CNN train_accuracy_list': [0.49796875, 0.50890625, 0.51875, 0.51984375, 0.52546875, 0.53421875, 0.5428125, 0.5665625, 0.5734375, 0.60984375, 0.63140625, 0.6471875, 0.69703125, 0.73125, 0.77203125, 0.82625, 0.87578125, 0.92546875, 0.97171875, 0.9928125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'MLP train_loss_list': [0.7008526921272278, 0.6782212853431702, 0.6566179394721985, 0.622295081615448, 0.5800589919090271, 0.5314801931381226, 0.47479331493377686, 0.4049808382987976, 0.32826438546180725, 0.2603800594806671, 0.1910039633512497, 0.1342652440071106, 0.09866520017385483, 0.07058674842119217, 0.050658781081438065, 0.03954479098320007, 0.032628439366817474, 0.027031034231185913, 0.023187657818198204, 0.020337803289294243, 0.018363863229751587, 0.016398757696151733, 0.015058020129799843, 0.013943632133305073, 0.012978218495845795, 0.012138644233345985, 0.011337105184793472, 0.010736116208136082, 0.010213668458163738, 0.009732622653245926], 'MLP train_accuracy_list': [0.510625, 0.5765625, 0.62296875, 0.66984375, 0.71328125, 0.7546875, 0.80015625, 0.84890625, 0.899375, 0.93625, 0.9671875, 0.98859375, 0.994375, 0.99890625, 0.99984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}
res_RL_WON = {'CNN train_loss_list': [0.6957153081893921, 0.6929060220718384, 0.693146824836731, 0.6927685141563416, 0.6923452019691467, 0.6921231150627136, 0.6918289661407471, 0.6914340257644653, 0.6910089254379272, 0.6911501884460449, 0.690055251121521, 0.6901530027389526, 0.6896100640296936, 0.6884787678718567, 0.6884654760360718, 0.6876795291900635, 0.6877204179763794, 0.6867640614509583, 0.6860294342041016, 0.6851438283920288, 0.6842660307884216, 0.6842423677444458, 0.6824518442153931, 0.6821364164352417, 0.6802919507026672, 0.6792766451835632, 0.677893877029419, 0.6768996119499207, 0.6748568415641785, 0.6740918755531311, 0.6714589595794678, 0.669880211353302, 0.6672102212905884, 0.6656893491744995, 0.663064181804657, 0.6595088243484497, 0.6583378314971924, 0.6545178294181824, 0.6507605314254761, 0.6484683156013489, 0.6449353694915771, 0.6403027176856995, 0.6362493634223938, 0.6337221264839172, 0.6289710998535156, 0.6240429878234863, 0.6203470230102539, 0.6157048940658569, 0.6113468408584595, 0.6066095232963562, 0.6007998585700989, 0.5944733619689941, 0.589614987373352, 0.5857372283935547, 0.5817388892173767, 0.5744847059249878, 0.5696008205413818, 0.5651178359985352, 0.5600252151489258, 0.5537959337234497, 0.5483062863349915, 0.5439490675926208, 0.539602518081665, 0.5335307717323303, 0.5314035415649414, 0.5252343416213989, 0.5209312438964844, 0.515518307685852, 0.5111974477767944, 0.5075404047966003, 0.5046434998512268, 0.4998689889907837, 0.49356549978256226, 0.4941989481449127, 0.48975250124931335, 0.4869634509086609, 0.4839136302471161, 0.4827660620212555, 0.4771474301815033, 0.477159708738327, 0.4733772575855255, 0.47056716680526733, 0.47309911251068115, 0.46551597118377686, 0.46494734287261963, 0.46438565850257874, 0.4609955847263336, 0.4626774191856384, 0.45886653661727905, 0.45755690336227417, 0.454248309135437, 0.4526948034763336, 0.45457008481025696, 0.449267715215683, 0.4456542432308197, 0.44822418689727783, 0.4447022080421448, 0.446492463350296, 0.44517573714256287, 0.4393037259578705, 0.44087645411491394, 0.4407843053340912, 0.4414471685886383, 0.4382072985172272, 0.4348560571670532, 0.4374893605709076, 0.4380301237106323, 0.43382352590560913, 0.431945264339447, 0.434736430644989, 0.43300262093544006, 0.43091610074043274, 0.43362879753112793, 0.4308103322982788, 0.4275239109992981, 0.4295886158943176, 0.42904651165008545, 0.42828428745269775, 0.4276687800884247, 0.4270392060279846, 0.4254331588745117, 0.4263975918292999, 0.4255024194717407, 0.4238933324813843, 0.4241674840450287, 0.42460334300994873, 0.4223625957965851, 0.42112648487091064, 0.42385736107826233, 0.42114147543907166, 0.4203953146934509, 0.4248850643634796, 0.41951173543930054, 0.41823112964630127, 0.41954606771469116, 0.41767656803131104, 0.41750368475914, 0.41619449853897095, 0.41702720522880554, 0.4175085723400116, 0.41720765829086304, 0.4178527593612671, 0.41666021943092346, 0.41572099924087524, 0.4160107672214508, 0.4164089858531952, 0.41513749957084656, 0.4137519598007202, 0.41634058952331543, 0.41453301906585693, 0.41221553087234497, 0.4154532253742218, 0.41387972235679626, 0.4126162528991699, 0.41214364767074585, 0.4123218357563019, 0.4121250808238983, 0.4129088521003723, 0.41028258204460144, 0.41146600246429443, 0.4121705889701843, 0.41115978360176086, 0.41008126735687256, 0.40993648767471313, 0.41140711307525635, 0.41367316246032715, 0.4098556935787201, 0.40840083360671997, 0.40987181663513184, 0.41030043363571167, 0.40805211663246155, 0.40904566645622253, 0.40850287675857544, 0.4088744521141052, 0.40655073523521423, 0.4079650044441223, 0.407795250415802, 0.40625014901161194, 0.4077907204627991, 0.4090448319911957, 0.40529149770736694, 0.4068698287010193, 0.40784022212028503, 0.4068352282047272, 0.40757036209106445, 0.40645626187324524, 0.4045791029930115, 0.40631818771362305, 0.4039827883243561, 0.4070185422897339, 0.40614816546440125, 0.4048653244972229, 0.40438398718833923, 0.4037373960018158, 0.40434515476226807, 0.40480536222457886, 0.402896523475647, 0.4051256775856018, 0.40386417508125305, 0.40362274646759033, 0.4055153429508209, 0.404397189617157, 0.4036164879798889, 0.4012242555618286, 0.40173763036727905, 0.4051571488380432, 0.4042775630950928, 0.40298891067504883, 0.40403255820274353, 0.40251845121383667, 0.40400445461273193, 0.40257391333580017, 0.4034575819969177, 0.4028378129005432, 0.40164703130722046, 0.40244489908218384, 0.4021588861942291, 0.4013212025165558, 0.4021719694137573, 0.4012133777141571, 0.4019193649291992, 0.40069499611854553, 0.40267470479011536, 0.4012044668197632, 0.40133175253868103, 0.40038734674453735, 0.40005815029144287, 0.40043607354164124, 0.3981669545173645, 0.40161094069480896, 0.40206408500671387, 0.4002860188484192, 0.40210437774658203, 0.3992224335670471, 0.4011102616786957, 0.3990379273891449, 0.4011429250240326, 0.40086135268211365, 0.4000413119792938, 0.3997195065021515, 0.40118545293807983, 0.39872387051582336, 0.39920687675476074, 0.39968714118003845, 0.3992336690425873, 0.3994080722332001, 0.3993200659751892, 0.39748793840408325, 0.39950841665267944, 0.3991970121860504], 'CNN train_accuracy_list': [0.50671875, 0.513125, 0.5140625, 0.515, 0.51484375, 0.514375, 0.51734375, 0.52390625, 0.5246875, 0.52609375, 0.5334375, 0.528125, 0.52546875, 0.54203125, 0.536875, 0.53859375, 0.53734375, 0.54203125, 0.5409375, 0.5484375, 0.549375, 0.54828125, 0.55625, 0.55578125, 0.55625, 0.555625, 0.56515625, 0.564375, 0.57453125, 0.57078125, 0.5775, 0.5759375, 0.5828125, 0.5925, 0.59609375, 0.596875, 0.5965625, 0.606875, 0.60984375, 0.61421875, 0.61875, 0.62390625, 0.6340625, 0.63046875, 0.63171875, 0.64453125, 0.63640625, 0.64890625, 0.65609375, 0.65953125, 0.661875, 0.66703125, 0.67671875, 0.67078125, 0.67609375, 0.6875, 0.69, 0.68359375, 0.69375, 0.70296875, 0.70484375, 0.7003125, 0.71140625, 0.7115625, 0.7153125, 0.711875, 0.7209375, 0.71734375, 0.724375, 0.728125, 0.728125, 0.7259375, 0.73265625, 0.73140625, 0.7375, 0.73328125, 0.7325, 0.73546875, 0.73859375, 0.73890625, 0.74546875, 0.74109375, 0.7390625, 0.7446875, 0.74140625, 0.740625, 0.74703125, 0.7390625, 0.74, 0.7434375, 0.74609375, 0.74984375, 0.7403125, 0.75359375, 0.75390625, 0.7521875, 0.74734375, 0.7453125, 0.748125, 0.74875, 0.75234375, 0.7471875, 0.74921875, 0.74890625, 0.75453125, 0.75328125, 0.74828125, 0.751875, 0.75453125, 0.7534375, 0.75625, 0.7534375, 0.74796875, 0.74828125, 0.7540625, 0.75046875, 0.75, 0.75234375, 0.74734375, 0.7565625, 0.7584375, 0.75421875, 0.74953125, 0.7540625, 0.75375, 0.74734375, 0.75203125, 0.7540625, 0.74828125, 0.7565625, 0.7528125, 0.74578125, 0.7553125, 0.754375, 0.7509375, 0.7528125, 0.75609375, 0.75546875, 0.75609375, 0.7559375, 0.7509375, 0.7546875, 0.75046875, 0.75578125, 0.75171875, 0.7521875, 0.7559375, 0.75828125, 0.75671875, 0.7525, 0.75421875, 0.74953125, 0.74921875, 0.75828125, 0.75359375, 0.75390625, 0.7525, 0.7534375, 0.75125, 0.75671875, 0.753125, 0.75578125, 0.75578125, 0.753125, 0.751875, 0.751875, 0.75671875, 0.75578125, 0.75359375, 0.75546875, 0.75296875, 0.75578125, 0.755, 0.751875, 0.7546875, 0.7525, 0.7509375, 0.7578125, 0.75625, 0.7509375, 0.7553125, 0.7546875, 0.75203125, 0.75796875, 0.75078125, 0.7578125, 0.75375, 0.75828125, 0.76234375, 0.74984375, 0.7496875, 0.7559375, 0.7575, 0.75515625, 0.75625, 0.75390625, 0.7553125, 0.7578125, 0.75890625, 0.75546875, 0.75015625, 0.755625, 0.7571875, 0.75921875, 0.761875, 0.753125, 0.74953125, 0.75453125, 0.75046875, 0.7596875, 0.75296875, 0.75578125, 0.7578125, 0.75359375, 0.75734375, 0.7546875, 0.75421875, 0.76, 0.75875, 0.7596875, 0.75703125, 0.7559375, 0.75421875, 0.7540625, 0.75640625, 0.75828125, 0.75796875, 0.75515625, 0.76, 0.7546875, 0.75140625, 0.75953125, 0.755625, 0.75859375, 0.75453125, 0.75859375, 0.7540625, 0.75453125, 0.75546875, 0.75359375, 0.7525, 0.75578125, 0.75796875, 0.7528125, 0.7571875, 0.75578125, 0.7571875, 0.75625, 0.759375, 0.75765625], 'MLP train_loss_list': [0.7001025080680847, 0.6943276524543762, 0.6913355588912964, 0.6908248662948608, 0.6890371441841125, 0.6873900294303894, 0.6857978701591492, 0.6850568056106567, 0.6842531561851501, 0.6820909976959229, 0.6798229217529297, 0.6793929934501648, 0.6782941222190857, 0.6755899786949158, 0.6723347902297974, 0.6714376211166382, 0.6694214344024658, 0.6675392985343933, 0.665542483329773, 0.6648217439651489, 0.6616026163101196, 0.6585647463798523, 0.6571947932243347, 0.6549787521362305, 0.6543008089065552, 0.650715172290802, 0.6487846374511719, 0.6454117298126221, 0.6431717276573181, 0.6424996256828308, 0.6405768990516663, 0.6334845423698425, 0.6327137351036072, 0.6305044889450073, 0.6272385120391846, 0.6243956089019775, 0.6248038411140442, 0.6203143000602722, 0.6183595657348633, 0.6185075044631958, 0.6142628788948059, 0.610440731048584, 0.6100916862487793, 0.6085461378097534, 0.6017172336578369, 0.6041499376296997, 0.5993437170982361, 0.5998800992965698, 0.5942855477333069, 0.594572901725769, 0.590041995048523, 0.5890382528305054, 0.5860137939453125, 0.5833101272583008, 0.5804493427276611, 0.5756058096885681, 0.579849362373352, 0.5719296336174011, 0.5685134530067444, 0.5674190521240234, 0.5656695365905762, 0.5622497200965881, 0.5628560781478882, 0.5584174990653992, 0.5576363801956177, 0.556404173374176, 0.5524282455444336, 0.5520026683807373, 0.5496736764907837, 0.5470144152641296, 0.5447638034820557, 0.5413353443145752, 0.5400510430335999, 0.540626049041748, 0.5373064875602722, 0.5350030064582825, 0.5321763753890991, 0.5310854315757751, 0.5286222696304321, 0.5262492299079895, 0.5248916149139404, 0.5246931314468384, 0.5246780514717102, 0.5211292505264282, 0.5199111700057983, 0.5149999856948853, 0.5172165632247925, 0.5109660029411316, 0.5150972008705139, 0.5111070275306702, 0.5124744176864624, 0.5087296366691589, 0.5077491998672485, 0.5071976184844971, 0.5015928745269775, 0.5062821507453918, 0.4987283945083618, 0.5020254850387573, 0.49801105260849, 0.495324969291687, 0.4981669485569, 0.4978042542934418, 0.49325311183929443, 0.4945882260799408, 0.4959646165370941, 0.4917140603065491, 0.48670732975006104, 0.4862612783908844, 0.48822927474975586, 0.4859408736228943, 0.48722410202026367, 0.483131468296051, 0.4840318262577057, 0.4811754524707794, 0.4815237820148468, 0.4795876443386078, 0.4755707085132599, 0.4756109118461609, 0.48069339990615845, 0.47839441895484924, 0.4755013585090637, 0.4762824773788452, 0.47283512353897095, 0.47245174646377563, 0.4723726809024811, 0.4730622470378876, 0.471786767244339, 0.47313299775123596, 0.4682568609714508, 0.4676174521446228, 0.46578291058540344, 0.4680383503437042, 0.4653100371360779, 0.4682692885398865, 0.46832770109176636, 0.46429651975631714, 0.46162116527557373, 0.46217286586761475, 0.46357160806655884, 0.46175214648246765, 0.4600962698459625, 0.46059608459472656, 0.4598442316055298, 0.45585474371910095, 0.45859938859939575, 0.45868560671806335, 0.4608045518398285, 0.45528337359428406, 0.45816102623939514, 0.45427030324935913, 0.4591063857078552, 0.45389315485954285, 0.4544880986213684, 0.4594000577926636, 0.4538303017616272, 0.45547106862068176, 0.4524841606616974, 0.44961273670196533, 0.4509811997413635, 0.4555930197238922, 0.4525970220565796, 0.45030510425567627, 0.4569242000579834, 0.4468792676925659, 0.45195120573043823, 0.4503418207168579, 0.44926467537879944, 0.44954824447631836, 0.44624099135398865, 0.4492444396018982, 0.44698455929756165, 0.44641637802124023, 0.4474615752696991, 0.4458664655685425, 0.44584667682647705, 0.4416695237159729, 0.44429346919059753, 0.4470778703689575, 0.449274480342865, 0.44460397958755493, 0.4438530504703522, 0.4417671859264374, 0.4454154074192047, 0.4414418637752533, 0.44163092970848083, 0.44095441699028015, 0.4427606463432312, 0.44213369488716125, 0.4427003264427185, 0.4399294853210449, 0.44113099575042725, 0.440373033285141, 0.4437774121761322, 0.43891090154647827, 0.443367063999176, 0.438516765832901, 0.4427888095378876, 0.44022977352142334, 0.4419810473918915, 0.4373033940792084, 0.4374196231365204, 0.43906763195991516, 0.43630605936050415, 0.43875548243522644, 0.4407195448875427, 0.4390997588634491, 0.4357779622077942, 0.4366873502731323, 0.4342733323574066, 0.43602079153060913, 0.4350072741508484, 0.43598681688308716, 0.4337596297264099, 0.43283897638320923, 0.43447765707969666, 0.4354247450828552, 0.4332975745201111, 0.4355982840061188, 0.43559134006500244, 0.43351271748542786, 0.4309242069721222, 0.43432867527008057, 0.43161195516586304, 0.4334980249404907, 0.43293997645378113, 0.43087831139564514, 0.4304477870464325, 0.4359751045703888, 0.4327086806297302, 0.43369483947753906, 0.43207216262817383, 0.43143707513809204, 0.43013375997543335, 0.43241086602211, 0.430519700050354, 0.43022364377975464, 0.4313840866088867, 0.42968592047691345, 0.43035945296287537, 0.4299079477787018, 0.43178611993789673, 0.4256493151187897, 0.42863044142723083, 0.4281678795814514, 0.4279283881187439, 0.4268744885921478, 0.4306623339653015, 0.43312421441078186, 0.42997172474861145, 0.42867597937583923], 'MLP train_accuracy_list': [0.48265625, 0.510625, 0.53421875, 0.5234375, 0.538125, 0.53765625, 0.54890625, 0.5521875, 0.55359375, 0.55921875, 0.566875, 0.57515625, 0.5671875, 0.57625, 0.5859375, 0.58109375, 0.59328125, 0.58703125, 0.59515625, 0.59640625, 0.59203125, 0.6084375, 0.60859375, 0.6115625, 0.6128125, 0.61609375, 0.618125, 0.62140625, 0.621875, 0.6253125, 0.62796875, 0.629375, 0.63265625, 0.63578125, 0.64484375, 0.6396875, 0.64671875, 0.64828125, 0.64609375, 0.6478125, 0.65, 0.65796875, 0.6546875, 0.65265625, 0.66546875, 0.66140625, 0.66484375, 0.66609375, 0.66484375, 0.6671875, 0.66984375, 0.6690625, 0.67484375, 0.6765625, 0.67296875, 0.68359375, 0.67953125, 0.6815625, 0.6871875, 0.6884375, 0.68703125, 0.69421875, 0.6965625, 0.69671875, 0.69203125, 0.6940625, 0.69625, 0.699375, 0.6925, 0.70109375, 0.70078125, 0.6996875, 0.70484375, 0.70421875, 0.7065625, 0.71234375, 0.70921875, 0.71078125, 0.715625, 0.7121875, 0.71578125, 0.7146875, 0.71546875, 0.71265625, 0.71859375, 0.7221875, 0.71953125, 0.726875, 0.72109375, 0.719375, 0.71640625, 0.72421875, 0.7228125, 0.7240625, 0.7240625, 0.72265625, 0.7253125, 0.72796875, 0.73046875, 0.73, 0.7296875, 0.7246875, 0.73546875, 0.7309375, 0.7234375, 0.7265625, 0.7371875, 0.73859375, 0.73515625, 0.73359375, 0.73359375, 0.73984375, 0.73765625, 0.733125, 0.73875, 0.7321875, 0.74515625, 0.73453125, 0.7375, 0.73640625, 0.745625, 0.739375, 0.745625, 0.74875, 0.741875, 0.746875, 0.74046875, 0.73875, 0.74140625, 0.73953125, 0.7471875, 0.74078125, 0.7446875, 0.74359375, 0.74640625, 0.7453125, 0.74453125, 0.74640625, 0.745, 0.7425, 0.7465625, 0.74875, 0.7478125, 0.754375, 0.7446875, 0.7471875, 0.7475, 0.7490625, 0.746875, 0.75078125, 0.74859375, 0.74859375, 0.74578125, 0.74390625, 0.74484375, 0.74515625, 0.75328125, 0.7540625, 0.74859375, 0.7446875, 0.7490625, 0.7496875, 0.7496875, 0.75609375, 0.7509375, 0.75296875, 0.74734375, 0.75484375, 0.7559375, 0.74875, 0.75609375, 0.751875, 0.749375, 0.7534375, 0.74953125, 0.75859375, 0.74953125, 0.75015625, 0.746875, 0.75234375, 0.7525, 0.75484375, 0.75328125, 0.75359375, 0.7553125, 0.7540625, 0.75484375, 0.7534375, 0.75171875, 0.7528125, 0.75421875, 0.75546875, 0.7459375, 0.7565625, 0.75, 0.75859375, 0.75046875, 0.76078125, 0.755, 0.75234375, 0.7596875, 0.75734375, 0.75421875, 0.7584375, 0.74984375, 0.75375, 0.7540625, 0.75859375, 0.7553125, 0.7578125, 0.75921875, 0.75640625, 0.759375, 0.76, 0.75625, 0.75171875, 0.75453125, 0.754375, 0.7559375, 0.75234375, 0.75921875, 0.75296875, 0.75953125, 0.7565625, 0.76234375, 0.76171875, 0.7596875, 0.755, 0.75640625, 0.75359375, 0.75796875, 0.760625, 0.75609375, 0.75515625, 0.75765625, 0.763125, 0.7540625, 0.7559375, 0.75890625, 0.7578125, 0.7625, 0.75953125, 0.7621875, 0.7603125, 0.76203125, 0.756875, 0.7540625, 0.7584375, 0.758125, 0.76]}
res_WON = {'CNN train_loss_list': [0.5208103060722351, 0.3873177766799927, 0.3312787711620331, 0.28822988271713257, 0.2530554234981537, 0.21636372804641724, 0.18168571591377258, 0.1442338079214096, 0.10705489665269852, 0.08853484690189362, 0.06273233890533447, 0.05654982104897499, 0.05439039692282677, 0.031244581565260887, 0.02547932043671608, 0.02103438414633274, 0.030439112335443497, 0.014316914603114128, 0.012970682233572006, 0.01165096927434206, 0.010898412205278873, 0.008490525186061859, 0.008014658465981483, 0.007272685412317514, 0.0061456249095499516, 0.005587141960859299, 0.00593583146110177, 0.005052038002759218, 0.00431550620123744, 0.004257802851498127, 0.004215484019368887, 0.003649081801995635, 0.0033539182040840387, 0.003782537765800953, 0.0031228740699589252, 0.0030084161553531885, 0.0028846224304288626, 0.002760515548288822, 0.0027928450144827366, 0.002391556976363063, 0.002369420602917671, 0.002427229657769203, 0.0023312990088015795, 0.002063579158857465, 0.002167444210499525, 0.0022343338932842016, 0.0019840665627270937, 0.0020597483962774277, 0.0018474222160875797, 0.0018359035020694137], 'CNN train_accuracy_list': [0.71325, 0.80525, 0.838, 0.867, 0.8895, 0.902, 0.92925, 0.9535, 0.9725, 0.973, 0.98875, 0.98675, 0.986, 0.9955, 0.997, 0.99775, 0.994, 1.0, 0.99975, 0.9995, 0.99975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'CNN test_loss_list': [0.10585597902536392, 0.09020211547613144, 0.08171436190605164, 0.07271597534418106, 0.07723921537399292, 0.05426221340894699, 0.04638422653079033, 0.04514383152127266, 0.028751695528626442, 0.03184451162815094, 0.02337587997317314, 0.014510449953377247, 0.020322492346167564, 0.009144170209765434, 0.008702239021658897, 0.0067171803675591946, 0.0058700875379145145, 0.005145295988768339, 0.004501495510339737, 0.005114821717143059, 0.0050576054491102695, 0.004187881946563721, 0.007037623785436153, 0.0031583064701408148, 0.00283058756031096, 0.0027031798381358385, 0.0028955021407455206, 0.002533608116209507, 0.0037021972239017487, 0.003373680403456092, 0.002051430055871606, 0.001955213025212288, 0.00192304328083992, 0.0020786928944289684, 0.002173064975067973, 0.0018003681907430291, 0.0017592472722753882, 0.0016768533969298005, 0.0018190642585977912, 0.0020139378029853106, 0.001877927570603788, 0.0017285834765061736, 0.0015100311720743775, 0.0014229813823476434, 0.0016640729736536741, 0.0013959136558696628, 0.0013618457596749067, 0.001356444088742137, 0.0013167798751965165, 0.0012719875667244196], 'CNN test_accuracy_list': [0.771, 0.808, 0.828, 0.857, 0.84, 0.902, 0.928, 0.919, 0.974, 0.94, 0.973, 0.987, 0.971, 0.997, 0.997, 0.998, 0.998, 0.999, 0.998, 0.996, 0.998, 0.998, 0.991, 0.998, 0.999, 0.999, 0.998, 0.999, 0.998, 0.998, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999], 'MLP train_loss_list': [0.5276119112968445, 0.42516013979911804, 0.38766688108444214, 0.35488221049308777, 0.3240833878517151, 0.29886677861213684, 0.27614298462867737, 0.26005780696868896, 0.24510984122753143, 0.22993223369121552, 0.2159152776002884, 0.20622655749320984, 0.1942821592092514, 0.18155279755592346, 0.17173689603805542, 0.16465704143047333, 0.15757937729358673, 0.14629574120044708, 0.14202380180358887, 0.13365891575813293, 0.12910839915275574, 0.12311676889657974, 0.11566037684679031, 0.11194946616888046, 0.10405752807855606, 0.10166572779417038, 0.09700608253479004, 0.09241583943367004, 0.08974564075469971, 0.08608949184417725, 0.08182626217603683, 0.07883034646511078, 0.07399806380271912, 0.07120200991630554, 0.069159135222435, 0.06546902656555176, 0.06490783393383026, 0.06035839021205902, 0.058853015303611755, 0.05603581294417381, 0.05425415188074112, 0.05246495455503464, 0.049618154764175415, 0.04825010150671005, 0.045793816447257996, 0.044683028012514114, 0.043685223907232285, 0.04179657995700836, 0.04050055146217346, 0.039139699190855026], 'MLP train_accuracy_list': [0.7015, 0.77225, 0.8065, 0.82925, 0.84775, 0.86125, 0.88125, 0.8895, 0.8985, 0.90575, 0.914, 0.91975, 0.92775, 0.93325, 0.93625, 0.945, 0.9465, 0.95225, 0.95675, 0.9585, 0.958, 0.9655, 0.96975, 0.96875, 0.97275, 0.97425, 0.97575, 0.9795, 0.97825, 0.98125, 0.983, 0.98525, 0.989, 0.98725, 0.99, 0.99125, 0.99225, 0.993, 0.99325, 0.994, 0.9955, 0.9955, 0.99725, 0.9985, 0.99725, 0.998, 0.9975, 0.99775, 0.99925, 0.99975], 'MLP test_loss_list': [0.1146475076675415, 0.1019047349691391, 0.09702186286449432, 0.0905982255935669, 0.08600794523954391, 0.08388108760118484, 0.07943159341812134, 0.07794852554798126, 0.07349348813295364, 0.0706925019621849, 0.07028704881668091, 0.06843321025371552, 0.06959807127714157, 0.06759069859981537, 0.06583910435438156, 0.06599051505327225, 0.06235498934984207, 0.06476542353630066, 0.06560792773962021, 0.06376085430383682, 0.06160726025700569, 0.06255396455526352, 0.06411293148994446, 0.06269191205501556, 0.060950346291065216, 0.06095944717526436, 0.060497913509607315, 0.0587468147277832, 0.05941738933324814, 0.06008809804916382, 0.06520285457372665, 0.06123298779129982, 0.05940357968211174, 0.057971660047769547, 0.0601566806435585, 0.05880579352378845, 0.06166096776723862, 0.05971752852201462, 0.060680948197841644, 0.059870414435863495, 0.05962345004081726, 0.05974310263991356, 0.059340693056583405, 0.060084134340286255, 0.06164396554231644, 0.05890757590532303, 0.059176813811063766, 0.05889984965324402, 0.06117299199104309, 0.06103063002228737], 'MLP test_accuracy_list': [0.751, 0.788, 0.802, 0.816, 0.828, 0.815, 0.832, 0.828, 0.848, 0.839, 0.852, 0.855, 0.85, 0.869, 0.852, 0.857, 0.873, 0.865, 0.856, 0.865, 0.875, 0.87, 0.871, 0.873, 0.871, 0.877, 0.876, 0.881, 0.884, 0.884, 0.877, 0.876, 0.882, 0.882, 0.881, 0.88, 0.883, 0.884, 0.89, 0.889, 0.889, 0.884, 0.892, 0.884, 0.884, 0.886, 0.889, 0.886, 0.881, 0.89]}

res_WN = {'CNN train_loss_list': [0.5090811848640442, 0.39783725142478943, 0.3594436049461365, 0.3204357326030731, 0.28426381945610046, 0.25206276774406433, 0.2188951075077057, 0.1880953311920166, 0.14721505343914032, 0.1173790916800499, 0.0895003080368042, 0.05794777348637581, 0.03999635949730873, 0.027566229924559593, 0.01951161026954651, 0.013978097587823868, 0.010877687484025955, 0.008909800089895725, 0.007568461820483208, 0.006438150070607662, 0.005628663115203381, 0.0050710695795714855, 0.004574168939143419, 0.004157926421612501, 0.0038401519414037466, 0.003594354260712862, 0.0033538558054715395, 0.0031620394438505173, 0.0030022466089576483, 0.0028531404677778482, 0.0027395556680858135, 0.0026144867297261953, 0.0025018409360200167, 0.0024249840062111616, 0.00233271112665534, 0.0022714382503181696, 0.0022087320685386658, 0.0021485837642103434, 0.002096401294693351, 0.0020447359420359135, 0.002001948654651642, 0.0019629085436463356, 0.0019287723116576672, 0.0018830716144293547, 0.0018574523273855448, 0.0018286326667293906, 0.0018020108109340072, 0.0017765015363693237, 0.0017489981837570667, 0.0017299954779446125], 'CNN train_accuracy_list': [0.71046875, 0.7815625, 0.8003125, 0.834375, 0.8565625, 0.87875, 0.901875, 0.92265625, 0.9428125, 0.96125, 0.97546875, 0.99234375, 0.99734375, 0.99953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'CNN test_loss_list': [0.11530432105064392, 0.1131838783621788, 0.10256332159042358, 0.09778257459402084, 0.09133285284042358, 0.09054423123598099, 0.09599775075912476, 0.08871793746948242, 0.09736757725477219, 0.10563191771507263, 0.09652342647314072, 0.0974392518401146, 0.1046571210026741, 0.10549010336399078, 0.1086164265871048, 0.11018464714288712, 0.11511879414319992, 0.11781740933656693, 0.11953167617321014, 0.11945313960313797, 0.12181128561496735, 0.12641704082489014, 0.1234312579035759, 0.12940509617328644, 0.12929144501686096, 0.12671047449111938, 0.13057973980903625, 0.1291879266500473, 0.1298595517873764, 0.12923318147659302, 0.13119859993457794, 0.13231585919857025, 0.1312674880027771, 0.1323683112859726, 0.13138283789157867, 0.13291509449481964, 0.13340499997138977, 0.13217055797576904, 0.13351760804653168, 0.13282108306884766, 0.1329818218946457, 0.1337047517299652, 0.1342322677373886, 0.13322292268276215, 0.13579167425632477, 0.1335182934999466, 0.1363389790058136, 0.1337675303220749, 0.13517117500305176, 0.13374274969100952], 'CNN test_accuracy_list': [0.725625, 0.738125, 0.75875, 0.78375, 0.793125, 0.80375, 0.795625, 0.809375, 0.804375, 0.804375, 0.82625, 0.81625, 0.819375, 0.820625, 0.823125, 0.82125, 0.8225, 0.823125, 0.82125, 0.821875, 0.82125, 0.821875, 0.82, 0.82125, 0.820625, 0.823125, 0.821875, 0.821875, 0.823125, 0.8225, 0.82, 0.8225, 0.8225, 0.8225, 0.8225, 0.821875, 0.82375, 0.824375, 0.81875, 0.820625, 0.82625, 0.82125, 0.823125, 0.821875, 0.821875, 0.823125, 0.825, 0.823125, 0.825, 0.823125], 'MLP train_loss_list': [0.5252740979194641, 0.42400026321411133, 0.3671392500400543, 0.30507323145866394, 0.24502408504486084, 0.18922732770442963, 0.13982783257961273, 0.10077842324972153, 0.07124537974596024, 0.05191069841384888, 0.038769349455833435, 0.030538951978087425, 0.02507038041949272, 0.021100174635648727, 0.017979634925723076, 0.015733182430267334, 0.014029241167008877, 0.012599559500813484, 0.011481638066470623, 0.010512168519198895, 0.009764017537236214, 0.009017106145620346, 0.00848113652318716, 0.007977772504091263, 0.007526795845478773, 0.0071281492710113525, 0.0067834798246622086, 0.006495807785540819, 0.006221533752977848, 0.005967431701719761, 0.005734041333198547, 0.005539977923035622, 0.005349632818251848, 0.0051955413073301315, 0.005028685089200735, 0.004893529694527388, 0.00476662814617157, 0.004640175029635429, 0.004527966491878033, 0.004433050751686096, 0.004329767543822527, 0.004244452808052301, 0.004169538617134094, 0.004083634354174137, 0.004015754442662001, 0.003950329497456551, 0.003885597689077258, 0.003817426273599267, 0.003756909631192684, 0.003707559546455741], 'MLP train_accuracy_list': [0.699375, 0.77796875, 0.82078125, 0.86515625, 0.906875, 0.94453125, 0.97078125, 0.98796875, 0.99703125, 0.999375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'MLP test_loss_list': [0.12336906045675278, 0.1222696527838707, 0.11962248384952545, 0.11675841361284256, 0.11770009994506836, 0.11761132627725601, 0.11953441053628922, 0.12535904347896576, 0.12759456038475037, 0.1302386373281479, 0.13401895761489868, 0.13494402170181274, 0.14053596556186676, 0.1405489444732666, 0.1423584222793579, 0.14627496898174286, 0.1456213891506195, 0.14859554171562195, 0.14806732535362244, 0.15175093710422516, 0.1504465639591217, 0.15216383337974548, 0.15308722853660583, 0.15451553463935852, 0.15491394698619843, 0.15515893697738647, 0.15685506165027618, 0.1574292629957199, 0.1575053483247757, 0.1577901393175125, 0.15726326406002045, 0.1589161902666092, 0.16012679040431976, 0.1590368002653122, 0.16075389087200165, 0.16005843877792358, 0.16088195145130157, 0.16059911251068115, 0.1605941206216812, 0.16278494894504547, 0.16090518236160278, 0.1617317497730255, 0.16217975318431854, 0.16200420260429382, 0.16269451379776, 0.16409818828105927, 0.16308556497097015, 0.16312211751937866, 0.16346099972724915, 0.16342687606811523], 'MLP test_accuracy_list': [0.736875, 0.723125, 0.7375, 0.750625, 0.76125, 0.7625, 0.769375, 0.769375, 0.774375, 0.77, 0.773125, 0.77625, 0.774375, 0.7825, 0.778125, 0.78, 0.778125, 0.78, 0.78, 0.78125, 0.78, 0.783125, 0.77875, 0.779375, 0.776875, 0.778125, 0.780625, 0.78125, 0.78375, 0.78, 0.780625, 0.778125, 0.78125, 0.78, 0.78125, 0.78, 0.779375, 0.779375, 0.779375, 0.780625, 0.780625, 0.780625, 0.780625, 0.780625, 0.780625, 0.78125, 0.78125, 0.78125, 0.780625, 0.77875]}
res_WON_MLP = {'MLP 800 train_loss_list': [0.48293960094451904, 0.3836566209793091, 0.33815819025039673, 0.29942548274993896, 0.26748278737068176, 0.24469642341136932, 0.22511236369609833, 0.20642350614070892, 0.19117678701877594, 0.17966890335083008, 0.16591252386569977, 0.15538327395915985, 0.14449170231819153, 0.13648070394992828, 0.1276036947965622, 0.12000031024217606, 0.11479868739843369, 0.10733696818351746, 0.10064787417650223, 0.0955381914973259, 0.09101469069719315, 0.08690067380666733, 0.08225551247596741, 0.07671050727367401, 0.07258820533752441, 0.06896182149648666, 0.0667494386434555, 0.06278984248638153, 0.06004995107650757, 0.05606761947274208, 0.05454606935381889, 0.052345823496580124, 0.04917793720960617, 0.047619666904211044, 0.045360710471868515, 0.043036654591560364, 0.04197167605161667, 0.0402737595140934, 0.03820382058620453, 0.0369267500936985, 0.035667937248945236, 0.034732162952423096, 0.03301316499710083, 0.031932931393384933, 0.030138645321130753, 0.029744789004325867, 0.029180504381656647, 0.027518557384610176, 0.026901545003056526, 0.026438215747475624], 'MLP 800 train_accuracy_list': [0.7384375, 0.809375, 0.83546875, 0.8659375, 0.8815625, 0.89765625, 0.90421875, 0.9178125, 0.92703125, 0.93125, 0.939375, 0.94640625, 0.95296875, 0.95234375, 0.95890625, 0.96375, 0.96625, 0.971875, 0.974375, 0.9740625, 0.97765625, 0.9775, 0.98125, 0.9821875, 0.9859375, 0.98671875, 0.9875, 0.98859375, 0.99078125, 0.9925, 0.9921875, 0.99296875, 0.99515625, 0.99484375, 0.99625, 0.99625, 0.99703125, 0.9984375, 0.99765625, 0.99765625, 0.9984375, 0.99875, 0.99875, 0.9996875, 0.9996875, 0.99984375, 0.99984375, 1.0, 0.9996875, 0.99984375], 'MLP 800 test_loss_list': [0.10684280842542648, 0.09585320949554443, 0.08738621324300766, 0.07777958363294601, 0.08006042242050171, 0.07172062993049622, 0.06587857753038406, 0.06747432798147202, 0.06277784705162048, 0.059489112347364426, 0.05733862146735191, 0.057247817516326904, 0.05354040488600731, 0.054348357021808624, 0.056114181876182556, 0.051801737397909164, 0.05463545769453049, 0.05067957937717438, 0.04758685082197189, 0.0509493425488472, 0.048166289925575256, 0.04620310664176941, 0.04678677022457123, 0.047650303691625595, 0.04587012156844139, 0.04682927578687668, 0.049235522747039795, 0.04470061510801315, 0.04631432518362999, 0.0465528778731823, 0.0445777103304863, 0.04383959621191025, 0.042918723076581955, 0.04254833981394768, 0.04272184148430824, 0.044413525611162186, 0.04375476762652397, 0.04331011697649956, 0.04252997785806656, 0.0427229143679142, 0.0432778000831604, 0.042462170124053955, 0.04406607523560524, 0.042130932211875916, 0.0438571460545063, 0.04392920061945915, 0.04359143599867821, 0.043363284319639206, 0.042572878301143646, 0.04419044777750969], 'MLP 800 test_accuracy_list': [0.745625, 0.82, 0.835625, 0.8525, 0.8425, 0.86125, 0.8675, 0.851875, 0.87625, 0.88125, 0.888125, 0.881875, 0.891875, 0.89, 0.876875, 0.891875, 0.879375, 0.9, 0.903125, 0.896875, 0.911875, 0.909375, 0.9125, 0.9075, 0.90625, 0.910625, 0.904375, 0.91375, 0.90625, 0.915625, 0.916875, 0.919375, 0.925, 0.921875, 0.924375, 0.9125, 0.919375, 0.92125, 0.92, 0.91875, 0.9175, 0.9225, 0.918125, 0.923125, 0.914375, 0.915, 0.9225, 0.920625, 0.92, 0.92], 'MLP 1600 train_loss_list': [0.47766509652137756, 0.376468688249588, 0.3250403106212616, 0.2878084182739258, 0.2543957233428955, 0.23309102654457092, 0.2114386260509491, 0.1933431178331375, 0.17775054275989532, 0.16514213383197784, 0.1525609940290451, 0.14112335443496704, 0.13329194486141205, 0.12196194380521774, 0.11478277295827866, 0.10797318071126938, 0.10198196768760681, 0.09507483243942261, 0.08919735997915268, 0.08456972241401672, 0.07945016026496887, 0.07418044656515121, 0.07130647450685501, 0.06714275479316711, 0.06332582980394363, 0.06023958697915077, 0.05716799199581146, 0.05376514792442322, 0.052227724343538284, 0.04879182577133179, 0.047025907784700394, 0.044943708926439285, 0.042658887803554535, 0.041188113391399384, 0.03921591490507126, 0.03744322061538696, 0.03609233722090721, 0.034793637692928314, 0.03301422297954559, 0.031776465475559235, 0.030642008408904076, 0.029586991295218468, 0.02865193784236908, 0.02745887264609337, 0.026813305914402008, 0.025759384036064148, 0.025074755772948265, 0.024216465651988983, 0.023437967523932457, 0.022802269086241722], 'MLP 1600 train_accuracy_list': [0.7421875, 0.815, 0.848125, 0.86484375, 0.8953125, 0.905625, 0.9184375, 0.93015625, 0.9346875, 0.9453125, 0.95078125, 0.954375, 0.95953125, 0.9628125, 0.968125, 0.96828125, 0.97328125, 0.97578125, 0.97984375, 0.98046875, 0.98296875, 0.9859375, 0.98703125, 0.9875, 0.989375, 0.9909375, 0.99328125, 0.99421875, 0.99375, 0.99625, 0.995625, 0.99640625, 0.9975, 0.9975, 0.9975, 0.9984375, 0.99875, 0.99921875, 0.9990625, 0.9996875, 0.99921875, 1.0, 1.0, 0.99984375, 0.99984375, 0.99984375, 1.0, 1.0, 1.0, 1.0], 'MLP 1600 test_loss_list': [0.10311008989810944, 0.09108100831508636, 0.08198779821395874, 0.07663281261920929, 0.07152745872735977, 0.06587187945842743, 0.06489779055118561, 0.06378205865621567, 0.05920758470892906, 0.060767751187086105, 0.05642230808734894, 0.05548753961920738, 0.05183229222893715, 0.054460279643535614, 0.05297739803791046, 0.049161147326231, 0.048504333943128586, 0.048057373613119125, 0.04795997217297554, 0.04479687288403511, 0.044202763587236404, 0.04416096583008766, 0.04336350038647652, 0.04599045589566231, 0.04289891943335533, 0.04203643649816513, 0.04339202120900154, 0.04343033209443092, 0.043895620852708817, 0.04244673252105713, 0.0410085991024971, 0.04224086180329323, 0.04288732260465622, 0.0409017950296402, 0.042193878442049026, 0.0422554686665535, 0.04127054288983345, 0.04167437553405762, 0.042582202702760696, 0.041473157703876495, 0.04253234341740608, 0.044004835188388824, 0.04232336953282356, 0.04157330468297005, 0.041438229382038116, 0.0406610369682312, 0.041171617805957794, 0.04140152409672737, 0.041648782789707184, 0.04082587733864784], 'MLP 1600 test_accuracy_list': [0.801875, 0.8175, 0.82625, 0.85125, 0.844375, 0.87625, 0.875, 0.85, 0.875, 0.884375, 0.8875, 0.895, 0.89625, 0.888125, 0.89, 0.9, 0.908125, 0.90375, 0.898125, 0.91625, 0.913125, 0.918125, 0.91625, 0.910625, 0.914375, 0.920625, 0.915, 0.916875, 0.915, 0.91875, 0.923125, 0.91875, 0.925, 0.925625, 0.92, 0.921875, 0.920625, 0.921875, 0.92125, 0.923125, 0.921875, 0.9175, 0.92, 0.921875, 0.9225, 0.923125, 0.923125, 0.9225, 0.921875, 0.92375], 'MLP 3200 train_loss_list': [0.4584493637084961, 0.36090102791786194, 0.3093808889389038, 0.27374503016471863, 0.24644392728805542, 0.22012656927108765, 0.20255300402641296, 0.18392260372638702, 0.16697782278060913, 0.15396663546562195, 0.14119692146778107, 0.13275884091854095, 0.12265782058238983, 0.11403863877058029, 0.10660455375909805, 0.09844960272312164, 0.0933111384510994, 0.08677666634321213, 0.08132213354110718, 0.07665041089057922, 0.07143088430166245, 0.06890928000211716, 0.06360220909118652, 0.05978980287909508, 0.05662169307470322, 0.05414190515875816, 0.05165674909949303, 0.04896584898233414, 0.046004489064216614, 0.04423587769269943, 0.04205714538693428, 0.04088650271296501, 0.03809827193617821, 0.0363771915435791, 0.03466031327843666, 0.03366289660334587, 0.03229578956961632, 0.03133181110024452, 0.029939543455839157, 0.028400352224707603, 0.027789436280727386, 0.02675233595073223, 0.025754868984222412, 0.024924013763666153, 0.023851541802287102, 0.023430459201335907, 0.022913722321391106, 0.022092239931225777, 0.021332062780857086, 0.02079138718545437], 'MLP 3200 train_accuracy_list': [0.76, 0.824375, 0.85796875, 0.88015625, 0.89359375, 0.91, 0.9225, 0.93546875, 0.94015625, 0.94484375, 0.95734375, 0.96015625, 0.964375, 0.96921875, 0.9721875, 0.97453125, 0.979375, 0.97890625, 0.985, 0.98453125, 0.9875, 0.9878125, 0.9909375, 0.99234375, 0.99328125, 0.9934375, 0.995625, 0.995, 0.99671875, 0.9978125, 0.99859375, 0.9978125, 0.99921875, 0.9984375, 0.99921875, 0.99921875, 0.9990625, 0.9996875, 0.99953125, 0.9996875, 0.99984375, 1.0, 0.9996875, 0.99984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99984375], 'MLP 3200 test_loss_list': [0.09948647022247314, 0.08702786266803741, 0.07801596820354462, 0.07484859973192215, 0.06695394217967987, 0.06487992405891418, 0.06136343255639076, 0.061284177005290985, 0.055995941162109375, 0.05681667849421501, 0.06133970990777016, 0.050860319286584854, 0.05083479359745979, 0.047663334757089615, 0.04888114333152771, 0.04726015031337738, 0.04939552769064903, 0.04410313069820404, 0.04417162016034126, 0.044641293585300446, 0.04494951292872429, 0.042922671884298325, 0.04534509405493736, 0.04189548268914223, 0.04134264960885048, 0.042518433183431625, 0.0428771898150444, 0.04214930906891823, 0.040988191962242126, 0.04085128381848335, 0.041663654148578644, 0.04034605994820595, 0.04033031314611435, 0.042501889169216156, 0.04061983898282051, 0.03979470953345299, 0.039675693958997726, 0.0395328626036644, 0.040169358253479004, 0.03970695286989212, 0.04000943899154663, 0.03954120725393295, 0.03966829553246498, 0.039718590676784515, 0.039841048419475555, 0.03975054249167442, 0.04011557623744011, 0.04000333324074745, 0.03945721685886383, 0.04003193601965904], 'MLP 3200 test_accuracy_list': [0.800625, 0.834375, 0.855, 0.835, 0.871875, 0.86125, 0.875, 0.876875, 0.88875, 0.888125, 0.873125, 0.898125, 0.89625, 0.91125, 0.903125, 0.905625, 0.904375, 0.90625, 0.911875, 0.915625, 0.904375, 0.920625, 0.910625, 0.92375, 0.9175, 0.914375, 0.91875, 0.91625, 0.92375, 0.925, 0.9225, 0.920625, 0.925, 0.92125, 0.924375, 0.925625, 0.920625, 0.925625, 0.9225, 0.92625, 0.9225, 0.925625, 0.925, 0.92375, 0.924375, 0.926875, 0.921875, 0.926875, 0.925625, 0.9275], 'MLP 6400 train_loss_list': [0.4481860399246216, 0.35156694054603577, 0.2958053946495056, 0.25605809688568115, 0.2281976044178009, 0.20290610194206238, 0.18418912589550018, 0.16680900752544403, 0.15242192149162292, 0.140411376953125, 0.1298399269580841, 0.11970734596252441, 0.10944797098636627, 0.10356910526752472, 0.0952424705028534, 0.08808878064155579, 0.08195552974939346, 0.07852978259325027, 0.0723222866654396, 0.0668647438287735, 0.06432001292705536, 0.06006375700235367, 0.055993154644966125, 0.052495937794446945, 0.04967822879552841, 0.04734339937567711, 0.044340550899505615, 0.0421818308532238, 0.04080857336521149, 0.037841204553842545, 0.03718545287847519, 0.03446412831544876, 0.03348759934306145, 0.032206740230321884, 0.03116428852081299, 0.029307769611477852, 0.028210369870066643, 0.0269403625279665, 0.02602747082710266, 0.0252838172018528, 0.024430977180600166, 0.02350563183426857, 0.02286016196012497, 0.021852800622582436, 0.021294904872775078, 0.02069837786257267, 0.02017640322446823, 0.01955685019493103, 0.01907818205654621, 0.018588589504361153], 'MLP 6400 train_accuracy_list': [0.7590625, 0.830625, 0.86421875, 0.88984375, 0.9046875, 0.920625, 0.9315625, 0.94328125, 0.94984375, 0.95890625, 0.95890625, 0.96515625, 0.97, 0.9734375, 0.9784375, 0.98015625, 0.985, 0.98375, 0.98859375, 0.9903125, 0.988125, 0.991875, 0.994375, 0.9953125, 0.99703125, 0.99671875, 0.9975, 0.99828125, 0.9984375, 0.99875, 0.99859375, 0.99953125, 0.9990625, 0.999375, 0.99984375, 0.99984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'MLP 6400 test_loss_list': [0.09827903658151627, 0.08570116013288498, 0.07514263689517975, 0.07019269466400146, 0.0661315992474556, 0.061592888087034225, 0.05969029292464256, 0.0573495514690876, 0.05303098261356354, 0.052388209849596024, 0.05140786990523338, 0.04918132722377777, 0.04891400411725044, 0.04636729508638382, 0.047159407287836075, 0.04592273011803627, 0.046751078218221664, 0.04414834454655647, 0.044945020228624344, 0.04930673912167549, 0.04226809740066528, 0.041708290576934814, 0.04317723959684372, 0.04328126460313797, 0.04244634509086609, 0.04082471877336502, 0.04187225550413132, 0.041807472705841064, 0.04048629850149155, 0.0407661609351635, 0.0406607985496521, 0.04064445570111275, 0.040191683918237686, 0.042247552424669266, 0.04025057330727577, 0.04045530781149864, 0.040706563740968704, 0.04103456810116768, 0.03993440419435501, 0.0407162643969059, 0.04097365587949753, 0.03871260955929756, 0.039896171540021896, 0.04015626758337021, 0.040392711758613586, 0.04061867669224739, 0.04016920551657677, 0.039877913892269135, 0.03975525498390198, 0.03967170789837837], 'MLP 6400 test_accuracy_list': [0.816875, 0.841875, 0.845, 0.861875, 0.87125, 0.86875, 0.874375, 0.886875, 0.901875, 0.89625, 0.893125, 0.901875, 0.903125, 0.9125, 0.901875, 0.91125, 0.9125, 0.91625, 0.913125, 0.898125, 0.91875, 0.92125, 0.9175, 0.91625, 0.920625, 0.923125, 0.919375, 0.919375, 0.924375, 0.92375, 0.9225, 0.925625, 0.925, 0.920625, 0.92625, 0.9275, 0.9225, 0.921875, 0.92625, 0.925625, 0.92375, 0.926875, 0.92625, 0.925625, 0.9225, 0.923125, 0.925, 0.92375, 0.928125, 0.925]}
res_WON_MLP_16000_samples = {'MLP train_loss_list': [0.3990882933139801, 0.2742719352245331, 0.21969278156757355, 0.18564364314079285, 0.16052024066448212, 0.13988302648067474, 0.12309224158525467, 0.10991652309894562, 0.09795497357845306, 0.08851198107004166, 0.08071582019329071, 0.07275184243917465, 0.06671749800443649, 0.06037455052137375, 0.05562056973576546, 0.0511409193277359, 0.04734039679169655, 0.04357440769672394, 0.04070030525326729, 0.0380094051361084, 0.03568623587489128, 0.03328554332256317, 0.03098461776971817, 0.029223607853055, 0.027717845514416695, 0.026427844539284706, 0.025174450129270554, 0.02373792603611946, 0.0228959321975708, 0.02214781939983368, 0.021396026015281677, 0.020664900541305542, 0.019869714975357056, 0.019090808928012848, 0.018563853576779366, 0.018206188455224037, 0.017677417024970055, 0.017062081024050713, 0.016866879537701607, 0.016483576968312263, 0.016142435371875763, 0.01582930237054825, 0.015565070323646069, 0.015177740715444088, 0.014977891929447651, 0.01485848892480135, 0.014656384475529194, 0.014429615810513496, 0.014172624796628952, 0.014132083393633366, 0.013957368209958076, 0.013839047402143478, 0.013618397526443005, 0.013485101982951164, 0.013323034159839153, 0.013310697861015797, 0.013260587118566036, 0.0130913769826293, 0.013094957917928696, 0.012973131611943245, 0.012799801304936409, 0.012751949951052666, 0.012688111513853073, 0.012606589123606682, 0.012567958794534206, 0.012452544644474983, 0.01247042790055275, 0.012433427385985851, 0.012323468923568726, 0.012242198921740055, 0.012311764992773533, 0.012212497182190418, 0.01218467764556408, 0.012068142183125019, 0.012079492211341858, 0.012027131393551826, 0.01202401239424944, 0.011968588456511497, 0.011963478289544582, 0.011931103654205799, 0.011942020617425442, 0.01184365525841713, 0.011835787445306778, 0.011716099455952644, 0.011788385920226574, 0.011776368133723736, 0.011781780049204826, 0.011703314259648323, 0.011716498993337154, 0.011705178767442703, 0.01165055576711893, 0.011650709435343742, 0.011611882597208023, 0.011616067960858345, 0.011595345102250576, 0.011533624492585659, 0.011547463946044445, 0.011479879729449749, 0.011509177275002003, 0.011476531624794006], 'MLP train_accuracy_list': [0.79546875, 0.8668359375, 0.8990234375, 0.9210546875, 0.9351953125, 0.9477734375, 0.9546875, 0.963203125, 0.9699609375, 0.9734375, 0.9773046875, 0.982109375, 0.9841015625, 0.986328125, 0.9891796875, 0.9903515625, 0.9919140625, 0.9933984375, 0.9941015625, 0.99484375, 0.9952734375, 0.99640625, 0.997421875, 0.997890625, 0.9982421875, 0.998515625, 0.9984375, 0.99890625, 0.9994140625, 0.9991796875, 0.9992578125, 0.999453125, 0.999609375, 0.999765625, 0.9998046875, 0.999609375, 0.999765625, 0.9998828125, 0.9998828125, 0.9998828125, 0.999921875, 1.0, 0.9998046875, 0.9999609375, 0.999921875, 1.0, 0.9999609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9998828125, 1.0, 1.0, 0.9999609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'MLP test_loss_list': [0.07818908244371414, 0.05904200300574303, 0.050236862152814865, 0.047754138708114624, 0.04241010546684265, 0.03669748827815056, 0.03283387050032616, 0.02972038835287094, 0.031094323843717575, 0.02507062442600727, 0.02442755363881588, 0.021633271127939224, 0.020194165408611298, 0.019709719344973564, 0.018253859132528305, 0.018002580851316452, 0.016644561663269997, 0.017421837896108627, 0.01691107451915741, 0.014957873150706291, 0.014612970873713493, 0.013551248237490654, 0.013260510750114918, 0.012850959785282612, 0.013223209418356419, 0.012339510954916477, 0.011537713930010796, 0.011791723780333996, 0.011468378826975822, 0.01137954369187355, 0.011033719405531883, 0.010469741187989712, 0.010426165536046028, 0.010175032541155815, 0.010223192162811756, 0.009678727015852928, 0.010106479749083519, 0.009831777773797512, 0.009539589285850525, 0.009340750053524971, 0.009520409628748894, 0.009615687653422356, 0.009666826575994492, 0.009836753830313683, 0.009932806715369225, 0.009103626012802124, 0.00947444699704647, 0.009176334366202354, 0.009505304507911205, 0.009423905983567238, 0.00908535998314619, 0.008865291252732277, 0.008877347223460674, 0.008868036791682243, 0.009318068623542786, 0.009053140878677368, 0.008920216001570225, 0.008998245000839233, 0.009045572951436043, 0.008688654750585556, 0.008720209822058678, 0.008774813264608383, 0.00841989554464817, 0.008491060696542263, 0.008485544472932816, 0.008700327947735786, 0.008961272425949574, 0.008579840883612633, 0.008627126924693584, 0.008769072592258453, 0.008479343727231026, 0.008351325988769531, 0.00859787967056036, 0.008465510793030262, 0.008853689767420292, 0.00825926847755909, 0.008546551689505577, 0.008367112837731838, 0.008218192495405674, 0.008779678493738174, 0.008281105197966099, 0.008574340492486954, 0.008141165599226952, 0.008327699266374111, 0.00818103551864624, 0.00842831376940012, 0.008168796077370644, 0.00805627554655075, 0.008364399895071983, 0.008203252218663692, 0.008071096614003181, 0.008112898096442223, 0.008159548044204712, 0.007986156269907951, 0.008231833577156067, 0.008155770599842072, 0.007922637276351452, 0.008461683988571167, 0.00806316640228033, 0.00830489955842495], 'MLP test_accuracy_list': [0.83109375, 0.88125, 0.90625, 0.9040625, 0.9140625, 0.93390625, 0.95109375, 0.9578125, 0.94828125, 0.9646875, 0.9634375, 0.9728125, 0.9746875, 0.97515625, 0.9775, 0.97671875, 0.97875, 0.976875, 0.976875, 0.98421875, 0.98484375, 0.98515625, 0.98625, 0.9853125, 0.98609375, 0.98546875, 0.98734375, 0.98734375, 0.98796875, 0.988125, 0.98765625, 0.9896875, 0.98890625, 0.98703125, 0.9890625, 0.98953125, 0.9890625, 0.98953125, 0.98953125, 0.99046875, 0.9890625, 0.988125, 0.99015625, 0.98765625, 0.98953125, 0.989375, 0.98859375, 0.98875, 0.988125, 0.98796875, 0.9896875, 0.98984375, 0.9890625, 0.989375, 0.98875, 0.98921875, 0.9890625, 0.989375, 0.98859375, 0.98875, 0.99, 0.98953125, 0.99046875, 0.99015625, 0.99, 0.98890625, 0.988125, 0.9896875, 0.98875, 0.98875, 0.99125, 0.98953125, 0.99015625, 0.989375, 0.98859375, 0.989375, 0.98921875, 0.99, 0.98953125, 0.99015625, 0.98953125, 0.98953125, 0.98953125, 0.989375, 0.99015625, 0.98828125, 0.99078125, 0.98921875, 0.9909375, 0.98984375, 0.99046875, 0.99015625, 0.9903125, 0.990625, 0.989375, 0.98953125, 0.9909375, 0.9903125, 0.99, 0.99046875]}
res_WON_MLP_8mil_params = {'MLP train_loss_list': [0.49670732021331787, 0.3899267911911011, 0.33669108152389526, 0.2968350946903229, 0.2723945379257202, 0.24554261565208435, 0.22655363380908966, 0.210834801197052, 0.1916857808828354, 0.17902863025665283, 0.16262269020080566, 0.15218955278396606, 0.14446616172790527, 0.13298234343528748, 0.12504200637340546, 0.11539353430271149, 0.10778859257698059, 0.1010395959019661, 0.094044990837574, 0.08879020810127258, 0.08393046259880066, 0.07722286880016327, 0.07328033447265625, 0.0689702108502388, 0.0649927482008934, 0.062349844723939896, 0.058200493454933167, 0.05473041534423828, 0.053062938153743744, 0.05127370357513428, 0.04729630425572395, 0.04555835947394371, 0.04311065375804901, 0.04121958091855049, 0.03942519798874855, 0.038572121411561966, 0.03626948595046997, 0.034969788044691086, 0.033231232315301895, 0.03191766142845154, 0.030883273109793663, 0.029809698462486267, 0.028885671868920326, 0.02766783908009529, 0.02716728113591671, 0.025986889377236366, 0.025277812033891678, 0.024224018678069115, 0.023489587008953094, 0.022774992510676384], 'MLP train_accuracy_list': [0.71825, 0.8, 0.83825, 0.875, 0.88175, 0.89825, 0.911, 0.91825, 0.935, 0.93775, 0.954, 0.95325, 0.962, 0.96625, 0.97475, 0.977, 0.978, 0.98325, 0.98475, 0.9875, 0.98725, 0.9905, 0.9935, 0.99325, 0.9965, 0.997, 0.99725, 0.997, 0.997, 0.99625, 0.99775, 0.999, 0.999, 0.99875, 0.99925, 0.999, 1.0, 0.99975, 1.0, 1.0, 0.99975, 1.0, 1.0, 1.0, 0.99975, 0.99975, 1.0, 1.0, 1.0, 1.0], 'MLP test_loss_list': [0.10892117768526077, 0.09399281442165375, 0.08815725892782211, 0.08046029508113861, 0.07811912894248962, 0.07248814404010773, 0.06680305302143097, 0.06552039831876755, 0.06526891142129898, 0.0587029904127121, 0.05854988470673561, 0.05463942140340805, 0.054656531661748886, 0.054951004683971405, 0.052654046565294266, 0.052253711968660355, 0.05152495205402374, 0.05080506578087807, 0.049073390662670135, 0.04886417090892792, 0.050136130303144455, 0.04728711396455765, 0.04807357117533684, 0.04672723263502121, 0.05057892948389053, 0.04560812935233116, 0.04568123817443848, 0.04626396298408508, 0.04565279558300972, 0.04416356980800629, 0.04494880884885788, 0.04452921450138092, 0.04466911777853966, 0.047643356025218964, 0.04561717435717583, 0.044634878635406494, 0.044769566506147385, 0.04555751383304596, 0.04545806720852852, 0.044404037296772, 0.04647282510995865, 0.04376761615276337, 0.04467320069670677, 0.04542871564626694, 0.04575492441654205, 0.04428545758128166, 0.04443797096610069, 0.04407856613397598, 0.046090204268693924, 0.04393552243709564], 'MLP test_accuracy_list': [0.763, 0.769, 0.783, 0.83, 0.819, 0.827, 0.859, 0.854, 0.859, 0.894, 0.887, 0.893, 0.892, 0.891, 0.89, 0.898, 0.9, 0.899, 0.902, 0.914, 0.911, 0.908, 0.913, 0.914, 0.903, 0.918, 0.908, 0.911, 0.915, 0.918, 0.909, 0.913, 0.912, 0.911, 0.913, 0.919, 0.918, 0.913, 0.915, 0.919, 0.917, 0.915, 0.918, 0.91, 0.913, 0.918, 0.918, 0.919, 0.917, 0.915]}

print(res_WON["CNN test_accuracy_list"])

plt.plot(res_WON_MLP_16000_samples["MLP test_accuracy_list"][:50], c="red", label="MLP with 16k samples")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.plot(res_WON_MLP_8mil_params["MLP test_accuracy_list"], c="purple", label="Over-parametrized MLP")
plt.legend()
plt.ylim([0.75,1.0])
plt.plot(res_WON["MLP test_accuracy_list"], c="blue", label="MLP")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.plot(res_WON["CNN test_accuracy_list"], c="green", label="CNN")
plt.legend()

# plt.plot(res_WN["CNN train_accuracy_list"], c="green", label="CNN on data with noise")
# plt.legend()
# plt.plot(res_WON["CNN train_accuracy_list"], c="purple", label="CNN on data without noise")
# plt.legend()

# plt.show()
plt.savefig(f'comparison test accuracy.png')